import{_ as n,r as i,o as l,c as h,a as t,b as o,w as a,d as e,e as d}from"./app.ff0cf306.js";const u={},c=t("h1",{id:"scaling-up-iv-flood-limits",tabindex:"-1"},[t("a",{class:"header-anchor",href:"#scaling-up-iv-flood-limits","aria-hidden":"true"},"#"),e(" Scaling Up IV: Flood Limits")],-1),m=e("Telegram restricts how many messages your bot can send per second, confer the "),_={href:"https://core.telegram.org/bots/faq#my-bot-is-hitting-limits-how-do-i-avoid-this",target:"_blank",rel:"noopener noreferrer"},p=e("Bot FAQ"),f=e(". You should always make sure to stay below these limits, otherwise your bot gets rate limited. If you ignore these errors, your bot may eventually be banned."),y=d('<h2 id="the-simple-solution" tabindex="-1"><a class="header-anchor" href="#the-simple-solution" aria-hidden="true">#</a> The Simple Solution</h2><div class="custom-container warning"><p class="custom-container-title">Not a Real Solution</p><p>This section solves your problem short-term, but if you are building a bot that should actually scale well, read the <a href="#the-real-solution-recommended">next subsection</a> instead.</p></div><p>There is a very simple solution to hitting rate limits: if an API request fails due to a rate limit, just wait the time Telegram tells you to wait, and repeat the request.</p>',3),g=e("If you want to do this, you can use the "),b=e("super simple "),w=t("code",null,[e("auto"),t("wbr"),e("-retry")],-1),v=e(" plugin"),x=e(". It is an "),k=e("API transformer function"),I=e(" that does exactly that."),T=t("p",null,"However, if the traffic to your bot increases rapidly, e.g. when it is added to a large group, it may run into a lot of rate limiting errors before the traffic spike settles. This could lead to a ban. Moreover, as requests might be tried several times, your server will consume more RAM and bandwidth than necessary. Instead of fixing the problem after the fact, it is much better to enqueue all API requests and only send them at the permitted speed:",-1),q=t("h2",{id:"the-real-solution-recommended",tabindex:"-1"},[t("a",{class:"header-anchor",href:"#the-real-solution-recommended","aria-hidden":"true"},"#"),e(" The Real Solution (recommended)")],-1),S=e("grammY provides you with the "),A=e("throttler plugin"),L=e(" that automatically makes your bot respect all rate limits by enqueuing the outgoing requests of your bot in a message queue. This plugin is just as simple to set up but does a much better job at flood control. There isn\u2019t really any good reason to use "),N=e("auto"),R=t("wbr",null,null,-1),V=e("-retry"),B=e(" over the "),j=e("throttler plugin"),E=e(". In some cases it may make sense to use both.");function P(C,F){const r=i("ExternalLinkIcon"),s=i("RouterLink");return l(),h("div",null,[c,t("p",null,[m,t("a",_,[p,o(r)]),f]),y,t("p",null,[g,o(s,{to:"/plugins/auto-retry.html"},{default:a(()=>[b,w,v]),_:1}),x,o(s,{to:"/advanced/transformers.html"},{default:a(()=>[k]),_:1}),I]),T,q,t("p",null,[S,o(s,{to:"/plugins/transformer-throttler.html"},{default:a(()=>[A]),_:1}),L,o(s,{to:"/plugins/auto-retry.html"},{default:a(()=>[N,R,V]),_:1}),B,o(s,{to:"/plugins/transformer-throttler.html"},{default:a(()=>[j]),_:1}),E])])}const Y=n(u,[["render",P],["__file","flood.html.vue"]]);export{Y as default};
